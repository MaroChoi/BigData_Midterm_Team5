# ğŸ“¦ ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ëª¨ìŒ (Full Functions)
import os
import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score, mean_squared_error


import matplotlib.pyplot as plt  # EDA ì‹œê°í™”ìš©
import seaborn as sns            # EDA ì‹œê°í™”ìš©

# 6ë‹¨ê³„: EDA ì‹œê°í™” í•¨ìˆ˜
def plot_categorical_distributions(df, categorical_cols):
    for col in categorical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.countplot(x=col, data=df)
            plt.title(f'Count Plot of {col}')
            plt.xticks(rotation=45)
            plt.show()

def plot_missing_heatmap(df):
    plt.figure(figsize=(10,6))
    sns.heatmap(df.isnull(), cbar=False, cmap="viridis")
    plt.title('Missing Value Heatmap')
    plt.show()

def plot_boxplots(df, numerical_cols):
    for col in numerical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.boxplot(x=df[col])
            plt.title(f'Boxplot of {col}')
            plt.show()

def plot_numeric_distributions(df, numerical_cols):
    for col in numerical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.histplot(df[col], kde=True, bins=30)
            plt.title(f'Distribution of {col}')
            plt.xlabel(col)
            plt.ylabel('Count')
            plt.show()

def plot_correlation_heatmap(df, numerical_cols):
    if len(numerical_cols) > 1:
        plt.figure(figsize=(8,6))
        corr = df[numerical_cols].corr()
        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Correlation Heatmap')
        plt.show()

def run_eda(df, numerical_cols, categorical_cols=None):
    print("\nğŸ“Š [1/5] ê²°ì¸¡ì¹˜ íˆíŠ¸ë§µ")
    plot_missing_heatmap(df)

    print("\nğŸ“Š [2/5] ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ Boxplot")
    plot_boxplots(df, numerical_cols)

    print("\nğŸ“Š [3/5] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ (Histplot)")
    plot_numeric_distributions(df, numerical_cols)

    if categorical_cols:
        print("\nğŸ“Š [4/5] ë²”ì£¼í˜• ë³€ìˆ˜ Count Plot")
        plot_categorical_distributions(df, categorical_cols)

    print("\nğŸ“Š [5/5] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (Heatmap)")
    plot_correlation_heatmap(df, numerical_cols)

    print("\nâœ… EDA ì‹œê°í™” ì™„ë£Œ.")


# 1ë‹¨ê³„: ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ì¶œë ¥ í•¨ìˆ˜
def inspect_unique_values(df, max_display=10):
    for col in df.columns:
        unique_vals = df[col].dropna().unique()
        print(f"\nğŸ” {col} (ê³ ìœ ê°’ {len(unique_vals)}ê°œ):")
        print(unique_vals[:max_display])
        if len(unique_vals) > max_display:
            print("... (ì´í•˜ ìƒëµ)")

# 2ë‹¨ê³„: ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ì²˜ë¦¬ í•¨ìˆ˜
def missing_value_handler_v2(df, numerical_cols, ordinal_numeric_cols, nominal_numeric_cols, ordinal_string_cols, nominal_string_cols):
    df = df.copy()
    df = df.drop_duplicates()
    missing_ratio = df.isnull().mean()
    cols_to_drop = missing_ratio[missing_ratio > 0.4].index.tolist()
    df.drop(columns=cols_to_drop, inplace=True)
    df = df.dropna(thresh=int(df.shape[1]*0.95))

    for col in df.columns:
        if df[col].isnull().sum() > 0:
            if col in numerical_cols:
                df[col] = df[col].fillna(df[col].median())
            elif col in ordinal_numeric_cols:
                df[col] = df[col].fillna(df[col].median())
            elif col in ordinal_string_cols:
                df[col] = df[col].fillna(df[col].mode()[0])
            elif col in nominal_numeric_cols:
                df[col] = df[col].fillna(df[col].mode()[0])
            elif col in nominal_string_cols:
                df[col] = df[col].fillna(df[col].mode()[0])
            else:
                df[col] = df[col].fillna('Unknown')
    return df

# ì¶”ê°€: Unknown ë˜ëŠ” NaNì´ ìˆëŠ” í–‰ ì‚­ì œ í•¨ìˆ˜
def drop_unknown_or_nan_rows(df, unknown_value='Unknown'):
    df = df.copy()
    condition = df.isnull().any(axis=1) | df.isin([unknown_value]).any(axis=1)
    df_cleaned = df[~condition].reset_index(drop=True)
    return df_cleaned

# 3ë‹¨ê³„: ìˆ˜ì¹˜í˜• ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ (IQR ë°©ì‹)
def remove_outliers_iqr(df, numerical_cols):
    df = df.copy()
    outlier_indices = set()
    for col in numerical_cols:
        if col in df.columns:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower) | (df[col] > upper)].index
            outlier_indices.update(outliers)
    df = df.drop(index=outlier_indices)
    return df

# 4ë‹¨ê³„: ë²”ì£¼í˜• ì¸ì½”ë”© í•¨ìˆ˜ë“¤
# 4-1-1 ìˆ«ìí˜•ì¸ë° ìˆœì„œ ìˆëŠ” ë°ì´í„°
def encode_ordinal_numeric(df, cols):
    df_encoded = df.copy()
    label_encoder = LabelEncoder()
    for col in cols:
        df_encoded[col] = label_encoder.fit_transform(df[col])
    return df_encoded
# 4-1-2 ìˆ«ìí˜•ì¸ë° ìˆœì„œ ì—†ëŠ” ë°ì´í„°
def encode_nominal_numeric(df, cols):
    df_encoded = pd.get_dummies(df, columns=cols)
    bool_cols = df_encoded.select_dtypes(include=['bool']).columns
    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)
    return df_encoded
# 4-2-1 ë¬¸ìí˜•ì¸ë° ìˆœì„œ ìˆëŠ” ë°ì´í„°
def encode_ordinal_string(df, cols):
    df_encoded = df.copy()
    label_encoder = LabelEncoder()
    for col in cols:
        df_encoded[col] = label_encoder.fit_transform(df[col])
    return df_encoded
# 4-2-2 ë¬¸ìí˜•ì¸ë° ìˆœì„œ ì—†ëŠ” ë°ì´í„°
def encode_nominal_string(df, cols):
    df_encoded = pd.get_dummies(df, columns=cols)
    bool_cols = df_encoded.select_dtypes(include=['bool']).columns
    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)
    return df_encoded

# 5ë‹¨ê³„: ì •ê·œí™” í•¨ìˆ˜ (MinMaxScaler / StandardScaler ì„ íƒ ê°€ëŠ¥)
def normalization_handler(df, numerical_cols, scaler_type='minmax'):
    df = df.copy()
    scaler = MinMaxScaler() if scaler_type == 'minmax' else StandardScaler()
    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
    return df


def some_function(input_file):
    import os

    # ì‚¬ìš©ì ì§€ì • ë¶€ë¶„ (ì›í•˜ëŠ” ì»¬ëŸ¼ë“¤)
    numerical_cols = ['ìˆ˜ì¹˜í˜• ì»¬ëŸ¼1', 'ìˆ˜ì¹˜í˜• ì»¬ëŸ¼2']  # âœ¨ ìˆ˜ì • í•„ìš”
    ordinal_numeric_cols = []
    nominal_numeric_cols = []
    ordinal_string_cols = []
    nominal_string_cols = []

    # íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(input_file)

    # ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ì²˜ë¦¬
    df = missing_value_handler_v2(df, numerical_cols, ordinal_numeric_cols, nominal_numeric_cols, ordinal_string_cols, nominal_string_cols)

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    selected_columns = ['ì›í•˜ëŠ” ì»¬ëŸ¼1', 'ì›í•˜ëŠ” ì»¬ëŸ¼2', 'ì›í•˜ëŠ” ì»¬ëŸ¼3']  # âœ¨ ìˆ˜ì • í•„ìš”
    df_selected = df[selected_columns]

    # ì´ìƒì¹˜ ì œê±°
    df_selected = remove_outliers_iqr(df_selected, numerical_cols=[col for col in numerical_cols if col in df_selected.columns])

    # Unknown/Nan í–‰ ì‚­ì œ
    df_selected = drop_unknown_or_nan_rows(df_selected)

    # âœ¨ íŒŒìƒë³€ìˆ˜ ì¶”ê°€
    df_selected['ìƒˆë¡œìš´_íŒŒìƒë³€ìˆ˜'] = df_selected['ì›í•˜ëŠ” ì»¬ëŸ¼1'] / (df_selected['ì›í•˜ëŠ” ì»¬ëŸ¼2'] + 1)

    # 5ê°œ ê·¸ë£¹ ì¬ë¶„ë¦¬ (â€» ì—¬ê¸° ì¤‘ìš”)
    numerical_cols_selected = [col for col in numerical_cols if col in df_selected.columns]
    ordinal_numeric_cols_selected = [col for col in ordinal_numeric_cols if col in df_selected.columns]
    nominal_numeric_cols_selected = [col for col in nominal_numeric_cols if col in df_selected.columns]
    ordinal_string_cols_selected = [col for col in ordinal_string_cols if col in df_selected.columns]
    nominal_string_cols_selected = [col for col in nominal_string_cols if col in df_selected.columns]

    # ìƒˆë¡œ ë§Œë“  íŒŒìƒë³€ìˆ˜ ì¶”ê°€
    numerical_cols_selected.append('ìƒˆë¡œìš´_íŒŒìƒë³€ìˆ˜')

    # 4ë‹¨ê³„: ë²”ì£¼í˜• ì¸ì½”ë”©
    df_encoded = df_selected.copy()
    if ordinal_numeric_cols_selected:
        df_encoded = encode_ordinal_numeric(df_encoded, ordinal_numeric_cols_selected)
    if nominal_numeric_cols_selected:
        df_encoded = encode_nominal_numeric(df_encoded, nominal_numeric_cols_selected)
    if ordinal_string_cols_selected:
        df_encoded = encode_ordinal_string(df_encoded, ordinal_string_cols_selected)
    if nominal_string_cols_selected:
        df_encoded = encode_nominal_string(df_encoded, nominal_string_cols_selected)

    # ì •ê·œí™” (â€» ì—¬ê¸° ìˆ˜ì •!!)
    df_encoded = normalization_handler(df_encoded, numerical_cols=numerical_cols_selected, scaler_type='minmax')

    # âœ¨ (í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ target ì¶”ê°€ ê°€ëŠ¥)

    # ìµœì¢… ì €ì¥
    save_folder = os.path.expanduser('~/Downloads')  # ë§¥ë¶ ê¸°ë³¸ Downloads í´ë”
    save_filename = 'final_preprocessed_data.csv'
    output_path = os.path.join(save_folder, save_filename)
    df_encoded.to_csv(output_path, index=False)

    # ê²°ê³¼ í™•ì¸
    print("\nâœ… ìµœì¢… ë°ì´í„°í”„ë ˆì„:")
    print(df_encoded.head())
    print(f"\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_path}")

    return output_path

# ğŸ”¥ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì‹œ (ì•„ë˜ ì½”ë“œ ì¶”ê°€)
df = pd.read_csv('C:/BigData_Midterm_Team5/BigData_Midterm_Team5/ì‹œí—˜ ë¬¸ì œ 1ë²ˆ/1_adults.csv')
# 1ë‹¨ê³„: ê³ ìœ ê°’ í™•ì¸
inspect_unique_values(df)

# ì»¬ëŸ¼ ì§ì ‘ êµ¬ë¶„
numerical_cols = ['age', 'hours.per.week']
ordinal_numeric_cols = ['education.num']
nominal_numeric_cols = []
ordinal_string_cols = ['education']
nominal_string_cols = ['workclass', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income']


# 2ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df = missing_value_handler_v2(df, numerical_cols, ordinal_numeric_cols, nominal_numeric_cols, ordinal_string_cols, nominal_string_cols)

# ì›í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ìƒˆë¡œìš´ DataFrame ë§Œë“¤ê¸°
selected_columns = [
    'age', 'workclass', 'education', 'education.num',
    'marital.status', 'occupation', 'relationship',
    'race', 'sex', 'hours.per.week', 'native.country', 'income'
]
df_selected = df[selected_columns]

# ì¶”ê°€: unkown+nan ì œê±°
df_selected = drop_unknown_or_nan_rows(df_selected)

# íŒŒìƒë³€ìˆ˜ ìƒì„± / gptì— ë¬¼ì–´ë´ 
# ì£¼ë‹¹ ê·¼ë¡œì‹œê°„(hours-per-week) Ã— 52ì£¼
df_selected['work_hours_per_year'] = df_selected['hours.per.week'] * 52


# 3ë‹¨ê³„: ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì´ìƒì¹˜ ì œê±° (IQR)
df_selected = remove_outliers_iqr(df_selected, [col for col in numerical_cols if col in df_selected.columns])

# 5ë‹¨ê³„: EDA ì‹¤í–‰
eda_numerical_cols = [col for col in numerical_cols if col in df_selected.columns] + ['work_hours_per_year']
run_eda(df_selected, numerical_cols=eda_numerical_cols)

# 5ê°œ ê·¸ë£¹ ì¬ë¶„ë¦¬
numerical_cols_selected = [col for col in numerical_cols if col in df_selected.columns]
ordinal_numeric_cols_selected = [col for col in ordinal_numeric_cols if col in df_selected.columns]
nominal_numeric_cols_selected = [col for col in nominal_numeric_cols if col in df_selected.columns]
ordinal_string_cols_selected = [col for col in ordinal_string_cols if col in df_selected.columns]
nominal_string_cols_selected = [col for col in nominal_string_cols if col in df_selected.columns]

# ìƒˆë¡œ ë§Œë“  íŒŒìƒë³€ìˆ˜ ì¶”ê°€
numerical_cols_selected.append('work_hours_per_year')

# 4ë‹¨ê³„: ë²”ì£¼í˜• ì¸ì½”ë”©
df_encoded = df_selected.copy()
if ordinal_numeric_cols_selected:
    df_encoded = encode_ordinal_numeric(df_encoded, ordinal_numeric_cols_selected)
if nominal_numeric_cols_selected:
    df_encoded = encode_nominal_numeric(df_encoded, nominal_numeric_cols_selected)
if ordinal_string_cols_selected:
    df_encoded = encode_ordinal_string(df_encoded, ordinal_string_cols_selected)
if nominal_string_cols_selected:
    df_encoded = encode_nominal_string(df_encoded, nominal_string_cols_selected)

# 5ë‹¨ê³„: ì •ê·œí™” ì ìš© (ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê¸°ì¤€, MinMaxScaler ë˜ëŠ” StandardScaler(logistic regression, linear regression) ì„ íƒ)
scaler_type = 'standard'  # 'minmax' ë˜ëŠ” 'standard' ì¤‘ ì„ íƒ ê°€ëŠ¥
df_encoded = normalization_handler(df_encoded, numerical_cols_selected, scaler_type=scaler_type)

# ê²°ê³¼ í™•ì¸
print("\nâœ… ìµœì¢… ë°ì´í„°í”„ë ˆì„:")
print(df_encoded.head())

# ìµœì¢… ì €ì¥
save_folder = os.path.expanduser('~/Downloads')  # ë§¥ë¶ ê¸°ë³¸ Downloads í´ë”
save_filename = 'final_preprocessed_data.csv'
output_path = os.path.join(save_folder, save_filename)
df_encoded.to_csv(output_path, index=False)


# âœ¨ ìµœì¢… ë°ì´í„° ì €ì¥
output_path = 'final_preprocessed_data.csv'
df_encoded.to_csv(output_path, index=False)
print(f"\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
