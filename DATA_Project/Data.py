# --- í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler
import re

# --- 1. í•„ìˆ˜ í•¨ìˆ˜ ì„ ì–¸ (ì „ì²˜ë¦¬, ì¸ì½”ë”©, ì •ê·œí™”, EDA) ---

# 1-1. ê³ ìœ ê°’ í™•ì¸ í•¨ìˆ˜
def inspect_unique_values(df, max_display=10):
    for col in df.columns:
        unique_vals = df[col].dropna().unique()
        print(f"\nğŸ” {col} (ê³ ìœ ê°’ {len(unique_vals)}ê°œ):")
        print(unique_vals[:max_display])
        if len(unique_vals) > max_display:
            print("... (ì´í•˜ ìƒëµ)")

# 1-2. ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ì²˜ë¦¬ í•¨ìˆ˜
def missing_value_handler_v2(df, numerical_cols, ordinal_numeric_cols, nominal_numeric_cols, ordinal_string_cols, nominal_string_cols):
    df = df.copy()
    df = df.drop_duplicates()
    missing_ratio = df.isnull().mean()
    cols_to_drop = missing_ratio[missing_ratio > 0.4].index.tolist()
    df.drop(columns=cols_to_drop, inplace=True)
    df = df.dropna(thresh=int(df.shape[1]*0.95))
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            if col in numerical_cols or col in ordinal_numeric_cols:
                df[col] = df[col].fillna(df[col].median())
            elif col in ordinal_string_cols or col in nominal_numeric_cols or col in nominal_string_cols:
                df[col] = df[col].fillna(df[col].mode()[0])
            else:
                df[col] = df[col].fillna('Unknown')
    return df

# 1-3. ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ (IQR ë°©ì‹)
def remove_outliers_iqr(df, numerical_cols):
    df = df.copy()
    outlier_indices = set()
    for col in numerical_cols:
        if col in df.columns:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower) | (df[col] > upper)].index
            outlier_indices.update(outliers)
    print(f"âœ… ì´ìƒì¹˜ ì œê±°: {len(outlier_indices)}ê°œ ë°ì´í„° ì‚­ì œë¨")
    df = df.drop(index=outlier_indices)
    return df

# 1-4. ì¸ì½”ë”© í•¨ìˆ˜ë“¤
def encode_ordinal_numeric(df, cols):
    df_encoded = df.copy()
    label_encoder = LabelEncoder()
    for col in cols:
        df_encoded[col] = label_encoder.fit_transform(df[col])
    return df_encoded

def encode_nominal_numeric(df, cols):
    df_encoded = pd.get_dummies(df, columns=cols)
    bool_cols = df_encoded.select_dtypes(include=['bool']).columns
    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)
    return df_encoded

def encode_ordinal_string(df, cols):
    df_encoded = df.copy()
    label_encoder = LabelEncoder()
    for col in cols:
        df_encoded[col] = label_encoder.fit_transform(df[col])
    return df_encoded

def encode_nominal_string(df, cols):
    df_encoded = pd.get_dummies(df, columns=cols)
    bool_cols = df_encoded.select_dtypes(include=['bool']).columns
    df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)
    return df_encoded

# 1-5. ì •ê·œí™” í•¨ìˆ˜
def normalization_handler(df, numerical_cols, scaler_type='minmax'):
    df = df.copy()
    scaler = MinMaxScaler() if scaler_type == 'minmax' else StandardScaler()
    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
    return df

# 1-6. EDA ë¸”ë¡
def plot_missing_heatmap(df):
    plt.figure(figsize=(10,6))
    sns.heatmap(df.isnull(), cbar=False, cmap="viridis")
    plt.title('Missing Value Heatmap')
    plt.show()

def plot_boxplots(df, numerical_cols):
    for col in numerical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.boxplot(x=df[col])
            plt.title(f'Boxplot of {col}')
            plt.show()

def plot_numeric_distributions(df, numerical_cols):
    for col in numerical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.histplot(df[col], kde=True, bins=30)
            plt.title(f'Distribution of {col}')
            plt.xlabel(col)
            plt.ylabel('Count')
            plt.show()

def plot_categorical_distributions(df, categorical_cols):
    for col in categorical_cols:
        if col in df.columns:
            plt.figure(figsize=(6,4))
            sns.countplot(x=col, data=df)
            plt.title(f'Count Plot of {col}')
            plt.xlabel(col)
            plt.ylabel('Count')
            plt.xticks(rotation=45)
            plt.show()

def plot_correlation_heatmap(df, numerical_cols):
    if len(numerical_cols) > 1:
        plt.figure(figsize=(8,6))
        corr = df[numerical_cols].corr()
        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Correlation Heatmap')
        plt.show()

def run_eda(df, numerical_cols, categorical_cols):
    print("\nğŸ“Š [1/5] ê²°ì¸¡ì¹˜ íˆíŠ¸ë§µ")
    plot_missing_heatmap(df)

    print("\nğŸ“Š [2/5] ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ Boxplot (ì´ìƒì¹˜ ì‹œê°í™”)")
    plot_boxplots(df, numerical_cols)

    print("\nğŸ“Š [3/5] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ (Histplot)")
    plot_numeric_distributions(df, numerical_cols)

    print("\nğŸ“Š [4/5] ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ (Countplot)")
    plot_categorical_distributions(df, categorical_cols)

    print("\nğŸ“Š [5/5] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (Heatmap)")
    plot_correlation_heatmap(df, numerical_cols)

    print("\nâœ… EDA ì‹œê°í™” ì™„ë£Œ.")

# ------------------------------------------------------------
# --- 2. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° -> ì „ì²˜ë¦¬ -> ì €ì¥)
# ------------------------------------------------------------

# 2-1. ë°ì´í„° ë¡œë“œ (ë‚˜ì¤‘ì— íŒŒì¼ ë„£ì„ ë•Œ ìˆ˜ì •)
df = pd.read_csv('íŒŒì¼_ê²½ë¡œë¥¼_ì—¬ê¸°ì—.csv')

# 2-2. ì»¬ëŸ¼ ë¶„ë¥˜ (ë‚˜ì¤‘ì— ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •)
numerical_cols = []  # ì˜ˆ: ['Age', 'Income']
ordinal_numeric_cols = []  # ì˜ˆ: ['Education_Level']
nominal_numeric_cols = []  # ì˜ˆ: ['Job_Type']
ordinal_string_cols = []  # ì˜ˆ: ['Satisfaction_Level']
nominal_string_cols = []  # ì˜ˆ: ['Gender', 'Country']

# 2-3. ê³ ìœ ê°’ í™•ì¸ (ë‚˜ì¤‘ì— df ë¡œë“œ í›„ ì‚¬ìš©)
inspect_unique_values(df)

# 2-4. ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ì²˜ë¦¬
df = missing_value_handler_v2(df, numerical_cols, ordinal_numeric_cols, nominal_numeric_cols, ordinal_string_cols, nominal_string_cols)

# 2-5. ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ
selected_columns = [col for col in (numerical_cols + ordinal_numeric_cols + nominal_numeric_cols + ordinal_string_cols + nominal_string_cols)]
df_selected = df[selected_columns].copy()

# 2-6. EDA ì‹œê°í™” (ì„ íƒì  ì‹¤í–‰)
categorical_cols = ordinal_numeric_cols + nominal_numeric_cols + ordinal_string_cols + nominal_string_cols
run_eda(df_selected, numerical_cols, categorical_cols)

# 2-7. íŒŒìƒë³€ìˆ˜ ì¶”ê°€ (ì—¬ê¸°ì„œ ì§ì ‘ ì¶”ê°€)
df_selected['new_feature'] = df_selected['Feature1'] / (df_selected['Feature2'] + 1)

# 2-8. ì´ìƒì¹˜ ì œê±°
df_selected = remove_outliers_iqr(df_selected, numerical_cols)

# 2-9. ë²”ì£¼í˜• ì¸ì½”ë”©
df_encoded = df_selected.copy()
if ordinal_numeric_cols:
    df_encoded = encode_ordinal_numeric(df_encoded, ordinal_numeric_cols)
if nominal_numeric_cols:
    df_encoded = encode_nominal_numeric(df_encoded, nominal_numeric_cols)
if ordinal_string_cols:
    df_encoded = encode_ordinal_string(df_encoded, ordinal_string_cols)
if nominal_string_cols:
    df_encoded = encode_nominal_string(df_encoded, nominal_string_cols)

# 2-10. Feature Leakage ì œê±° (íƒ€ê²Ÿ ê´€ë ¨ ì»¬ëŸ¼ ì œê±° í•„ìš”)
X = df_encoded.drop(['Target_Yes', 'Target_No'], axis=1)
y = df_encoded['Target_Yes']

# 2-11. ìˆ˜ì¹˜í˜• ì •ê·œí™”
scaler_type = 'minmax'  # ë˜ëŠ” 'standard'
X = normalization_handler(X, numerical_cols, scaler_type=scaler_type)

# 2-12. ìµœì¢… ë°ì´í„° ì €ì¥
output_path = 'preprocessed_data.csv'
final_df_for_save = pd.concat([X, y], axis=1)
final_df_for_save.to_csv(output_path, index=False)

# 2-13. ëª¨ë¸ í•™ìŠµ (Logistic Regression)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("\nğŸ¯ Logistic Regression ìµœì¢… ì„±ëŠ¥ í‰ê°€:")
print("ì •í™•ë„ (Accuracy):", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
